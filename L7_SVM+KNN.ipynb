{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Âê≥_W7_SVM+KNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgPaHa1tUClb",
        "colab_type": "code",
        "outputId": "20d6eef6-d47c-4f10-aa66-4e2df4d6084e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from IPython.display import Image\n",
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# inline plotting instead of popping out\n",
        "%matplotlib inline\n",
        "\n",
        "# load utility classes/functions that has been taught in previous labs\n",
        "# e.g., plot_decision_regions()\n",
        "import os, sys\n",
        "module_path = os.path.abspath(os.path.join('.'))\n",
        "sys.path.append(module_path)\n",
        "!pip install lib\n",
        "from lib import *"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lib in /usr/local/lib/python3.6/dist-packages (3.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH80VTgq4sdp",
        "colab_type": "code",
        "outputId": "9fc2655a-e6ea-49d8-e116-871d5138de16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "#Nonlinearly Separable Classes\n",
        "#Sometimes, the classes in a dataset may be nonlinearly separable. \n",
        "#A famous synthetic dataset in this category, called the two-moon dataset\n",
        "from sklearn.datasets import make_moons\n",
        "X, y = make_moons(n_samples=100, noise=0.15, random_state=0)\n",
        "plt.scatter(X[y == 0, 0], X[y == 0, 1],\n",
        "            c='r', marker='o', label='Class 0')\n",
        "plt.scatter(X[y == 1, 0], X[y == 1, 1],\n",
        "            c='b', marker='s', label='Class 1')\n",
        "\n",
        "plt.xlim(X[:, 0].min()-1, X[:, 0].max()+1)\n",
        "plt.ylim(X[:, 1].min()-1, X[:, 1].max()+1)\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend(loc='best')\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig-two-moon.png', dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D7xfWLH5tQw",
        "colab_type": "code",
        "outputId": "340cea62-2ea0-4b16-a286-c16ae1de1e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        }
      },
      "source": [
        "#If we apply linear classifiers such as Perceptron or Logistic Regression to this dataset, \n",
        "#it is not possible to get a reasonable decision boundary:\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "sc = StandardScaler()\n",
        "sc.fit(X_train)\n",
        "X_train_std = sc.transform(X_train)\n",
        "X_test_std = sc.transform(X_test)\n",
        "\n",
        "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
        "y_combined = np.hstack((y_train, y_test))\n",
        "\n",
        "ppn = Perceptron(max_iter=1000, eta0=0.1, random_state=0)\n",
        "ppn.fit(X_train_std, y_train)\n",
        "y_pred = ppn.predict(X_test_std)\n",
        "print('[Perceptron]')\n",
        "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
        "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
        "\n",
        "# plot decision regions for Perceptron\n",
        "plot_decision_regions(X_combined_std, y_combined,\n",
        "                      clf=ppn, \n",
        "                      filler_feature_ranges=range(y_train.size, \n",
        "                                     y_train.size + y_test.size))\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend(loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig-two-moon-perceptron-boundray.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "lr = LogisticRegression(C=1000.0, random_state=0)\n",
        "#C default 1.0ÔºåÁÇ∫Ê≠£Ë¶èÂåñ‰øÇÊï∏ŒªÁöÑÂÄíÊï∏ÔºåÂøÖÈúÄÊòØÊ≠£Êï∏!(ÂèçÊ≠£Ë¶èÂåñ)„ÄÇÂÄºÊÑàÂ∞èÔºåÂâáÊ≠£Ë¶èÂåñË∂äÈ´ò„ÄÇ\n",
        "lr.fit(X_train_std, y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test_std)\n",
        "print('[Logistic regression]')\n",
        "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
        "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
        "\n",
        "# plot decision regions for LogisticRegression\n",
        "plot_decision_regions(X_combined_std, y_combined,\n",
        "                      clf=lr, \n",
        "                      filler_feature_ranges=range(y_train.size, \n",
        "                                     y_train.size + y_test.size))\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend(loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig-two-moon-logistic-regression-boundray.png', dpi=300)\n",
        "plt.show()\n",
        "#the models are too simple to capture the shape of true boundary, introducing a large bias"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Perceptron]\n",
            "Misclassified samples: 3\n",
            "Accuracy: 0.85\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nO/gAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Logistic regression]\n",
            "Misclassified samples: 3\n",
            "Accuracy: 0.85\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEfEkBZSIiHjS/wEdquUEWWHCUgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la0bBNmLPql1",
        "colab_type": "text"
      },
      "source": [
        "# **K-Nearest Neighbors Classifier**\n",
        "The KNN algorithm itself is fairly straightforward and can be summarized by the following steps:\n",
        "\n",
        "\n",
        "\n",
        "1.   Choose K (the number of neighbors), and a distance metric;\n",
        "2.   Find the K nearest neighbors of the data point that we want to classify;\n",
        "3.   Assign the class label by majority vote.\n",
        "\n",
        "KNN is a typical example of a **lazy** learner. It is called lazy because it simply memorizes the training dataset in the training phase and learns a discriminative function f only before making a prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzTeeqE-PUok",
        "colab_type": "code",
        "outputId": "9e8964dc-46f9-4ec8-ce43-05200e7a450c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# p=2 and metric='minkowski' means the Euclidean Distance, K=n_neighbors=11\n",
        "knn = KNeighborsClassifier(n_neighbors=11, p=2, metric='minkowski')\n",
        "knn.fit(X_train_std, y_train)\n",
        "y_pred = knn.predict(X_test_std)\n",
        "print('[KNN]')\n",
        "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
        "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
        "\n",
        "# plot decision regions for knn classifier\n",
        "plot_decision_regions(X_combined_std, y_combined,\n",
        "                      clf=knn, \n",
        "                      filler_feature_ranges=range(y_train.size,\n",
        "                                     y_train.size + y_test.size))\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend(loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig-two-moon-knn-boundray.png', dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[KNN]\n",
            "Misclassified samples: 1\n",
            "Accuracy: 0.95\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAUVERLrEgCIiIl36f+VVJq49OiAaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYc5-OlxQ0a6",
        "colab_type": "text"
      },
      "source": [
        "**advantage** of such a memory-based approach is that the classifier **immediately adapts** as we collect new training data.\n",
        "\n",
        "However, the **downside** is that the **computational complexity for classifying new points** grows linearly with the **number of samples in the training dataset** in the worst-case scenario, unless the dataset has very few dimensions (features) and the algorithm has been implemented using efficient data structures such as KD-trees, an algorithm for finding best matches in logarithmic expected time. Furthermore, **we can't discard training samples since no training step is involved**. Thus, **storage space** can become a challenge if we are working with large datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR42GGbvRRC7",
        "colab_type": "text"
      },
      "source": [
        "### Support Vector Classifier\n",
        "Another powerful and widely used memory-based classifier is the nonlinear support vector classifier (SVC). Like KNN, nonlinear SVC makes predictions by the weighted average of the labels of similar examples (measured by a kernel function). However, only the **support vectors**, i.e., examples falling onto or inside the margin, can have positive weights and need to be remembered. In practice, SVC usually remembers much fewer examples than KNN does. Another difference is that SVC is not an lazy learner---the weights are trained eagerly in the training phase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8vPWNhVQuls",
        "colab_type": "code",
        "outputId": "2c9906ff-0934-420b-851f-8e4303958637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "# kernel: the kernel function, can be 'linear', 'poly', 'rbf', ...etc\n",
        "# C is the hyperparameter for the error penalty term\n",
        "#C maximizing margin and minimizing slacks\n",
        "svm_linear = SVC(kernel='linear', C=1000.0, random_state=0)\n",
        "\n",
        "svm_linear.fit(X_train_std, y_train)\n",
        "y_pred = svm_linear.predict(X_test_std)\n",
        "print('[Linear SVC]')\n",
        "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
        "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
        "\n",
        "# plot decision regions for linear svm\n",
        "plot_decision_regions(X_combined_std, y_combined,\n",
        "                      clf=svm_linear, \n",
        "                      filler_feature_ranges=range(y_train.size,\n",
        "                                     y_train.size + y_test.size))\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend(loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.savefig('figtwo-moon-svm-linear-boundray.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# C is the hyperparameter for the error penalty term\n",
        "# gamma is the hyperparameter for the rbf kernel\n",
        "svm_rbf = SVC(kernel='rbf', random_state=0, gamma=0.2, C=10.0)\n",
        "\n",
        "svm_rbf.fit(X_train_std, y_train)\n",
        "y_pred = svm_rbf.predict(X_test_std)\n",
        "print('[Nonlinear SVC]')\n",
        "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
        "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
        "\n",
        "# plot decision regions for rbf svm\n",
        "plot_decision_regions(X_combined_std, y_combined,\n",
        "                      clf=svm_rbf, \n",
        "                      filler_feature_ranges=range(y_train.size, \n",
        "                                     y_train.size + y_test.size))\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend(loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig-two-moon-svm-rbf-boundray.png', dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Linear SVC]\n",
            "Misclassified samples: 3\n",
            "Accuracy: 0.85\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[Nonlinear SVC]\n",
            "Misclassified samples: 1\n",
            "Accuracy: 0.95\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unzyY_LHbr8P",
        "colab_type": "code",
        "outputId": "6edd74f9-c251-4295-d4c2-1312193b2744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print('[Nonlinear SVC: C=1000, gamma=0.01]')\n",
        "svm = SVC(kernel='rbf', random_state=0, gamma=0.01, C=1000.0)\n",
        "svm.fit(X_train_std, y_train)\n",
        "y_pred = svm.predict(X_test_std)\n",
        "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
        "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
        "\n",
        "print('\\n[Nonlinear SVC: C=1, gamma=0.0001]')\n",
        "svm = SVC(kernel='rbf', random_state=0, gamma=0.0001, C=10.0)\n",
        "svm.fit(X_train_std, y_train)\n",
        "y_pred = svm.predict(X_test_std)\n",
        "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
        "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Nonlinear SVC: C=1000, gamma=0.01]\n",
            "Misclassified samples: 3\n",
            "Accuracy: 0.85\n",
            "\n",
            "[Nonlinear SVC: C=1, gamma=0.0001]\n",
            "Misclassified samples: 11\n",
            "Accuracy: 0.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soN3EC97cAqN",
        "colab_type": "text"
      },
      "source": [
        "### Tuning Hyperparameters via Grid Search\n",
        "In SVC, there is no simple way to relate a particular hyperparameter combination (C,Œ≥) to the model complexity. So, we have to **try out all possible (or specified) combinations exhaustively** in order to pick the best one. This procedure is called **grid search**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIuWm06Ab-BD",
        "colab_type": "code",
        "outputId": "70e326d4-1c56-499c-ebf1-e8a0c6fca0c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_C = [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]\n",
        "param_gamma = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0]\n",
        "\n",
        "svm = SVC(random_state=0)\n",
        "\n",
        "# set the param_grid parameter of GridSearchCV to a list of dictionaries\n",
        "param_grid = [{'C': param_C, \n",
        "               'gamma': param_gamma, \n",
        "               'kernel': ['rbf']}]\n",
        "gs = GridSearchCV(estimator=svm, \n",
        "                  param_grid=param_grid, \n",
        "                  scoring='accuracy')\n",
        "\n",
        "gs = gs.fit(X_train_std, y_train)\n",
        "print(gs.best_score_)\n",
        "print(gs.best_params_)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9875\n",
            "{'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a725AA1_dWTc",
        "colab_type": "code",
        "outputId": "027b59f8-b128-448e-9771-febeaa163e62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "clf = gs.best_estimator_\n",
        "clf.fit(X_train_std, y_train)\n",
        "print('\\n[Nonlinear SVC: grid search]')\n",
        "print('Test accuracy: %.2f' % clf.score(X_test_std, y_test))\n",
        "\n",
        "# plot decision regions for rbf svm\n",
        "plot_decision_regions(X_combined_std, y_combined,\n",
        "                      clf=gs.best_estimator_, \n",
        "                      filler_feature_ranges=range(y_train.size, \n",
        "                                     y_train.size + y_test.size))\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend(loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.savefig('fig-two-moon-svm-rbf-gs-boundray.png', dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Nonlinear SVC: grid search]\n",
            "Test accuracy: 1.00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOWyoT7vdeEN",
        "colab_type": "text"
      },
      "source": [
        "### Data Preprocessing\n",
        "The quality of the data and the amount of useful information that it contains are key factors that determine how well a machine learning algorithm can learn. Therefore, it is critical that we make sure to examine and **preprocess** a dataset before we feed it to a learning algorithm. The dataset we use on next section is the Adult dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2WHItlbdoJB",
        "colab_type": "code",
        "outputId": "bec098f7-56bd-40ef-c3ae-69615f69ba8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# we set sep=', ' since this dataset is not a regular csv file\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/'\n",
        "                 'adult/adult.data', header=None, sep=', ', engine='python')\n",
        "\n",
        "df.columns = ['age', 'workclass', 'fnlwgt', 'education', \n",
        "              'education-num', 'marital-status', 'occupation', \n",
        "              'relationship', 'race', 'sex', 'capital-gain', \n",
        "              'capital-loss', 'hours-per-week', 'native-country', \n",
        "              'label']\n",
        "\n",
        "display(df.head(15))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>37</td>\n",
              "      <td>Private</td>\n",
              "      <td>284582</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>49</td>\n",
              "      <td>Private</td>\n",
              "      <td>160187</td>\n",
              "      <td>9th</td>\n",
              "      <td>5</td>\n",
              "      <td>Married-spouse-absent</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>Jamaica</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>52</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>209642</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>31</td>\n",
              "      <td>Private</td>\n",
              "      <td>45781</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>14084</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>42</td>\n",
              "      <td>Private</td>\n",
              "      <td>159449</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>5178</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>37</td>\n",
              "      <td>Private</td>\n",
              "      <td>280464</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>30</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>141297</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Asian-Pac-Islander</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>India</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>23</td>\n",
              "      <td>Private</td>\n",
              "      <td>122272</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>32</td>\n",
              "      <td>Private</td>\n",
              "      <td>205019</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>12</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>40</td>\n",
              "      <td>Private</td>\n",
              "      <td>121772</td>\n",
              "      <td>Assoc-voc</td>\n",
              "      <td>11</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Asian-Pac-Islander</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>?</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age         workclass  fnlwgt  ... hours-per-week  native-country  label\n",
              "0    39         State-gov   77516  ...             40   United-States  <=50K\n",
              "1    50  Self-emp-not-inc   83311  ...             13   United-States  <=50K\n",
              "2    38           Private  215646  ...             40   United-States  <=50K\n",
              "3    53           Private  234721  ...             40   United-States  <=50K\n",
              "4    28           Private  338409  ...             40            Cuba  <=50K\n",
              "5    37           Private  284582  ...             40   United-States  <=50K\n",
              "6    49           Private  160187  ...             16         Jamaica  <=50K\n",
              "7    52  Self-emp-not-inc  209642  ...             45   United-States   >50K\n",
              "8    31           Private   45781  ...             50   United-States   >50K\n",
              "9    42           Private  159449  ...             40   United-States   >50K\n",
              "10   37           Private  280464  ...             80   United-States   >50K\n",
              "11   30         State-gov  141297  ...             40           India   >50K\n",
              "12   23           Private  122272  ...             30   United-States  <=50K\n",
              "13   32           Private  205019  ...             50   United-States  <=50K\n",
              "14   40           Private  121772  ...             40               ?   >50K\n",
              "\n",
              "[15 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUcA3LUFdqZ_",
        "colab_type": "text"
      },
      "source": [
        "### We can observe two things in this dataset:\n",
        "\n",
        "\n",
        "\n",
        "1.   Many attributes are not numeric but categorical;\n",
        "2.   There are missing values. For example, data point No.14 has a missing value on native-country.\n",
        "\n",
        "Since most machine learning algorithms can only take datasets with numeric features and without missing values. We have to preprocess this dataset.\n",
        "\n",
        "### Handling Categorical Data\n",
        "Real-world datasets usually contain one or more categorical features. When we are talking about categorical data, we have to further distinguish between nominal and ordinal features. Ordinal features can be understood as categorical values that can be sorted or ordered. For example, T-shirt size would be an ordinal feature, because we can define an order XL > L > M. In contrast, nominal features don't imply any order. For example, we could think of T-shirt color as a nominal feature since it typically doesn't make sense to say that, for example, red is larger than blue.\n",
        "\n",
        "In the Adult dataset, there is no obvious feature that is ordinal. So we will only focus on nominal ones in this lab. We can use the **LabelEncoder in scikit-learn to help us encode categorical values into numerical values.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ8sbu0qdy2h",
        "colab_type": "code",
        "outputId": "2889e575-b309-430c-fb4f-d0e5536d3618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# encode label first\n",
        "label_le = LabelEncoder()\n",
        "df['label'] = label_le.fit_transform(df['label'].values)\n",
        "\n",
        "# encode categorical features\n",
        "catego_features = ['workclass', 'education', 'marital-status', 'occupation', \n",
        "                   'relationship', 'race', 'sex', 'native-country']\n",
        "\n",
        "catego_le = LabelEncoder()\n",
        "\n",
        "# transform categorical values into numerical values\n",
        "# be careful that '?' will also be encoded\n",
        "# we have to replace it to NaN in numerical\n",
        "num_values = []\n",
        "for i in catego_features:\n",
        "    df[i] = catego_le.fit_transform(df[i].values)\n",
        "    classes_list = catego_le.classes_.tolist()\n",
        "    \n",
        "    # store the total number of values\n",
        "    num_values.append(len(classes_list))\n",
        "    \n",
        "    # replace '?' with 'NaN'\n",
        "    if '?' in classes_list:\n",
        "        idx = classes_list.index('?')\n",
        "        df[i] = df[i].replace(idx, np.nan)\n",
        "\n",
        "display(df.head(15))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>7.0</td>\n",
              "      <td>77516</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>6.0</td>\n",
              "      <td>83311</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>4.0</td>\n",
              "      <td>215646</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>4.0</td>\n",
              "      <td>234721</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>4.0</td>\n",
              "      <td>338409</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>37</td>\n",
              "      <td>4.0</td>\n",
              "      <td>284582</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>49</td>\n",
              "      <td>4.0</td>\n",
              "      <td>160187</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>52</td>\n",
              "      <td>6.0</td>\n",
              "      <td>209642</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>31</td>\n",
              "      <td>4.0</td>\n",
              "      <td>45781</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>14084</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>159449</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5178</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>37</td>\n",
              "      <td>4.0</td>\n",
              "      <td>280464</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>30</td>\n",
              "      <td>7.0</td>\n",
              "      <td>141297</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>23</td>\n",
              "      <td>4.0</td>\n",
              "      <td>122272</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>32</td>\n",
              "      <td>4.0</td>\n",
              "      <td>205019</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>40</td>\n",
              "      <td>4.0</td>\n",
              "      <td>121772</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age  workclass  fnlwgt  ...  hours-per-week  native-country  label\n",
              "0    39        7.0   77516  ...              40            39.0      0\n",
              "1    50        6.0   83311  ...              13            39.0      0\n",
              "2    38        4.0  215646  ...              40            39.0      0\n",
              "3    53        4.0  234721  ...              40            39.0      0\n",
              "4    28        4.0  338409  ...              40             5.0      0\n",
              "5    37        4.0  284582  ...              40            39.0      0\n",
              "6    49        4.0  160187  ...              16            23.0      0\n",
              "7    52        6.0  209642  ...              45            39.0      1\n",
              "8    31        4.0   45781  ...              50            39.0      1\n",
              "9    42        4.0  159449  ...              40            39.0      1\n",
              "10   37        4.0  280464  ...              80            39.0      1\n",
              "11   30        7.0  141297  ...              40            19.0      1\n",
              "12   23        4.0  122272  ...              30            39.0      0\n",
              "13   32        4.0  205019  ...              50            39.0      0\n",
              "14   40        4.0  121772  ...              40             NaN      1\n",
              "\n",
              "[15 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyCTeJBveDMC",
        "colab_type": "text"
      },
      "source": [
        "### Dealing with Missing Data\n",
        "It is common in real-world applications that our samples have missing values for various reasons in one or more attributes for various reasons. For example, there could have been an error in the data collection process, or certain measurements are not applicable, or particular fields could have been left blank intentionally in a survey, etc. We typically see missing values as the blank spaces, NaN, or question mark in our datasets.\n",
        "\n",
        "Unfortunately, most computational tools are unable to handle such missing values or would produce unpredictable results if we simply ignored them. Therefore, it is crucial that we take care of those missing values before we proceed with further analyses.\n",
        "\n",
        "First, we can use **isnull()** method **in Panda's Dataframe** to see how many missing values we have in Adult dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXwLjde6eIho",
        "colab_type": "code",
        "outputId": "8186413b-8942-4ac5-e623-262478214cc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# count the number of missing values per column\n",
        "display(df.isnull().sum())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "age                  0\n",
              "workclass         1836\n",
              "fnlwgt               0\n",
              "education            0\n",
              "education-num        0\n",
              "marital-status       0\n",
              "occupation        1843\n",
              "relationship         0\n",
              "race                 0\n",
              "sex                  0\n",
              "capital-gain         0\n",
              "capital-loss         0\n",
              "hours-per-week       0\n",
              "native-country     583\n",
              "label                0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE8HJ02YeLzU",
        "colab_type": "text"
      },
      "source": [
        "For a larger dataset, it can be tedious to look for missing values manually; in this case, we can use the isnull() method to return a DataFrame with **Boolean values** that indicate whether a cell contains a numeric value (False) or if data is missing (True). Using the sum() method, we can then return the number of missing values per column.\n",
        "\n",
        "Next, we discuss some different strategies to handle missing data.\n",
        "\n",
        "### Eliminating Samples or Features with Missing Values\n",
        "\n",
        "One of the easiest ways to deal with missing data is to simply remove the corresponding features (columns) or samples (rows) from the dataset entirely. We can call the **dropna()** method of Dataframe **to eliminate rows or columns**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StZm29vQeTcn",
        "colab_type": "code",
        "outputId": "509314b8-52a6-48bc-ad11-5e66cde2096f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(df.shape)\n",
        "\n",
        "# drop rows with missing values\n",
        "df_drop_row = df.dropna()\n",
        "print(df_drop_row.shape)\n",
        "#The dropna method supports several additional parameters that can come in handy:\n",
        "print('Original: {}'.format(df.shape))\n",
        "\n",
        "# drop columns with missing values\n",
        "df_drop_col = df.dropna(axis=1)\n",
        "print('Drop column: {}'.format(df_drop_col.shape))\n",
        "\n",
        "# drop rows or columns where all values are NaN\n",
        "df_drop_row_all = df.dropna(how='all')\n",
        "print('Drop row all: {}'.format(df_drop_row_all.shape))\n",
        "\n",
        "# keep rows that have at least 14 non-NaN values\n",
        "df_drop_row_thresh = df.dropna(thresh=14)\n",
        "print('Drop row 14: {}'.format(df_drop_row_thresh.shape))\n",
        "\n",
        "# only drop rows where NaN appear in specific columns (here: 'occupation')\n",
        "df_drop_row_occupation = df.dropna(subset=['occupation'])\n",
        "print('Drop row occupation: {}'.format(df_drop_row_occupation.shape))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32561, 15)\n",
            "(30162, 15)\n",
            "Original: (32561, 15)\n",
            "Drop column: (32561, 12)\n",
            "Drop row all: (32561, 15)\n",
            "Drop row 14: (30725, 15)\n",
            "Drop row occupation: (30718, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7ygITYYeag8",
        "colab_type": "text"
      },
      "source": [
        "Although the removal of missing data seems to be a convenient approach, it comes with certain disadvantages; for example, we may end up removing too many samples and have a small dataset, resulting in overfitting. Or, if we remove too many feature columns, we will run the risk of losing valuable relationship between features that our classifier needs to discriminate between classes.\n",
        "\n",
        "### Imputing Missing Values\n",
        "\n",
        "If we do not have a large dataset, the removal of samples or dropping of entire feature columns may not be feasible, because we could lose too much valuable information. An alternative way is to **use interpolation techniques to estimate the missing values from other training samples in the same dataset**. There are some common interpolation techniques we can use, such as **mean** imputation, **median** imputation, and **most frequent** imputation.\n",
        "\n",
        "\n",
        "The Imputer class from scikit-learn provides a convenient way for imputation. Next, we use it to perform the most frequent imputation since the missing values in the Adult dataset are all categorical features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nKJxekueet_",
        "colab_type": "code",
        "outputId": "814f6b24-8b39-46d9-bbcf-c1116576cb90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.preprocessing import Imputer\n",
        "\n",
        "imr = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)\n",
        "imr = imr.fit(df.values)\n",
        "imputed_data = imr.transform(df.values)\n",
        "\n",
        "df_impute = pd.DataFrame(imputed_data)\n",
        "df_impute.columns = df.columns\n",
        "\n",
        "display(df.head(15))\n",
        "display(df_impute.head(15))\n",
        "\n",
        "# check if there are still missing values\n",
        "display(df_impute.isnull().sum())"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>7.0</td>\n",
              "      <td>77516</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>6.0</td>\n",
              "      <td>83311</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>4.0</td>\n",
              "      <td>215646</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>4.0</td>\n",
              "      <td>234721</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>4.0</td>\n",
              "      <td>338409</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>37</td>\n",
              "      <td>4.0</td>\n",
              "      <td>284582</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>49</td>\n",
              "      <td>4.0</td>\n",
              "      <td>160187</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>52</td>\n",
              "      <td>6.0</td>\n",
              "      <td>209642</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>31</td>\n",
              "      <td>4.0</td>\n",
              "      <td>45781</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>14084</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>159449</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5178</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>37</td>\n",
              "      <td>4.0</td>\n",
              "      <td>280464</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>30</td>\n",
              "      <td>7.0</td>\n",
              "      <td>141297</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>23</td>\n",
              "      <td>4.0</td>\n",
              "      <td>122272</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>32</td>\n",
              "      <td>4.0</td>\n",
              "      <td>205019</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>40</td>\n",
              "      <td>4.0</td>\n",
              "      <td>121772</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age  workclass  fnlwgt  ...  hours-per-week  native-country  label\n",
              "0    39        7.0   77516  ...              40            39.0      0\n",
              "1    50        6.0   83311  ...              13            39.0      0\n",
              "2    38        4.0  215646  ...              40            39.0      0\n",
              "3    53        4.0  234721  ...              40            39.0      0\n",
              "4    28        4.0  338409  ...              40             5.0      0\n",
              "5    37        4.0  284582  ...              40            39.0      0\n",
              "6    49        4.0  160187  ...              16            23.0      0\n",
              "7    52        6.0  209642  ...              45            39.0      1\n",
              "8    31        4.0   45781  ...              50            39.0      1\n",
              "9    42        4.0  159449  ...              40            39.0      1\n",
              "10   37        4.0  280464  ...              80            39.0      1\n",
              "11   30        7.0  141297  ...              40            19.0      1\n",
              "12   23        4.0  122272  ...              30            39.0      0\n",
              "13   32        4.0  205019  ...              50            39.0      0\n",
              "14   40        4.0  121772  ...              40             NaN      1\n",
              "\n",
              "[15 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>77516.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2174.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>83311.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>215646.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>234721.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>338409.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>37.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>284582.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>49.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>160187.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>52.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>209642.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>31.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>45781.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14084.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>42.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>159449.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5178.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>37.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>280464.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>30.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>141297.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>23.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>122272.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>32.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>205019.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>40.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>121772.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  workclass    fnlwgt  ...  hours-per-week  native-country  label\n",
              "0   39.0        7.0   77516.0  ...            40.0            39.0    0.0\n",
              "1   50.0        6.0   83311.0  ...            13.0            39.0    0.0\n",
              "2   38.0        4.0  215646.0  ...            40.0            39.0    0.0\n",
              "3   53.0        4.0  234721.0  ...            40.0            39.0    0.0\n",
              "4   28.0        4.0  338409.0  ...            40.0             5.0    0.0\n",
              "5   37.0        4.0  284582.0  ...            40.0            39.0    0.0\n",
              "6   49.0        4.0  160187.0  ...            16.0            23.0    0.0\n",
              "7   52.0        6.0  209642.0  ...            45.0            39.0    1.0\n",
              "8   31.0        4.0   45781.0  ...            50.0            39.0    1.0\n",
              "9   42.0        4.0  159449.0  ...            40.0            39.0    1.0\n",
              "10  37.0        4.0  280464.0  ...            80.0            39.0    1.0\n",
              "11  30.0        7.0  141297.0  ...            40.0            19.0    1.0\n",
              "12  23.0        4.0  122272.0  ...            30.0            39.0    0.0\n",
              "13  32.0        4.0  205019.0  ...            50.0            39.0    0.0\n",
              "14  40.0        4.0  121772.0  ...            40.0            39.0    1.0\n",
              "\n",
              "[15 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "age               0\n",
              "workclass         0\n",
              "fnlwgt            0\n",
              "education         0\n",
              "education-num     0\n",
              "marital-status    0\n",
              "occupation        0\n",
              "relationship      0\n",
              "race              0\n",
              "sex               0\n",
              "capital-gain      0\n",
              "capital-loss      0\n",
              "hours-per-week    0\n",
              "native-country    0\n",
              "label             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz_BKoMCei90",
        "colab_type": "text"
      },
      "source": [
        "### One-Hot Encoding\n",
        "If we stop at this point and feed the array to our classifier, we will make one of the most common **mistakes** in dealing with categorical data. Take the 'workclass' for example, we will assume that 'State-gov' is larger than 'Self-emp-not-inc', and 'Self-emp-not-inc' is larger than 'Private'. This **incorrect assumption can lead to degraded performance**. For example, if a model uses weight decay for regularization, it may prefer categorical values that are encoded closer to 0.\n",
        "\n",
        "A common workaround for this problem is to use a technique called **one-hot encoding**. The idea behind this approach is to **create a new dummy feature column for each unique value in the nominal feature**. To perform this transformation, we can use the **OneHotEncoder from Scikit-learn**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47U4yKwKenYm",
        "colab_type": "code",
        "outputId": "b7b2be12-604a-4c2e-9070-e179922eb6c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# we perform one-hot encoding on both impute data and drop-row data\n",
        "impute_data = df_impute.values\n",
        "drop_row_data = df_drop_row.values\n",
        "\n",
        "# find the index of the categorical feature\n",
        "catego_features_idx = []\n",
        "for fea in catego_features:\n",
        "    catego_features_idx.append(df.columns.tolist().index(fea))\n",
        "\n",
        "# give the column index you want to do one-hot encoding\n",
        "ohe = OneHotEncoder(categorical_features = catego_features_idx, sparse=False)\n",
        "\n",
        "impute_onehot_data = ohe.fit_transform(impute_data)\n",
        "print('Impute: {}'.format(impute_data.shape))\n",
        "print('Impute one-hot: {}'.format(impute_onehot_data.shape))\n",
        "\n",
        "drop_row_onehot_data = ohe.fit_transform(drop_row_data)\n",
        "print('Drop row: {}'.format(drop_row_data.shape))\n",
        "print('Drop row one-hot: {}'.format(drop_row_onehot_data.shape))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Impute: (32561, 15)\n",
            "Impute one-hot: (32561, 106)\n",
            "Drop row: (30162, 15)\n",
            "Drop row one-hot: (30162, 105)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiMRU4-OepkT",
        "colab_type": "text"
      },
      "source": [
        "Here, we can see that the numbers of column on both dataset increase significantly. Note that the number of columns between impute_onehot_data and drop_row_onehot_data are different, which implies that **the drop-row method makes a value in a column disappear, resulting in loss of information**.\n",
        "\n",
        "NOTE: by default, the OneHotEncoder returns a sparse matrix when we use the transform() method. Sparse matrices save space to store entries with a lot of zeros.\n",
        "\n",
        "### The get_dummies() Method in Pandas\n",
        "An alternative, but more convenient way to **create dummy features** via one-hot encoding is to use the **get_dummies() method implemented in Pandas.**\n",
        "\n",
        "NOTE: the get_dummies() method will **only convert string columns and leave all other columns unchanged**. If you want to use this method, **you have to ensure that the categorical data are all string**. Otherwise it will not perform encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e5C1pv8evmM",
        "colab_type": "code",
        "outputId": "19cd729e-6de6-4aab-8338-f8aa2cf2de06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "df_dummy = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/'\n",
        "                 'adult/adult.data',\n",
        "                 header=None, sep=', ', engine='python')\n",
        "\n",
        "df_dummy.columns = ['age', 'workclass', 'fnlwgt', 'education', \n",
        "                    'education-num', 'marital-status', 'occupation', \n",
        "                    'relationship', 'race', 'sex', 'capital-gain', \n",
        "                    'capital-loss', 'hours-per-week', 'native-country', \n",
        "                    'label']\n",
        "\n",
        "# encode label first\n",
        "label_le = LabelEncoder()\n",
        "df_dummy['label'] = label_le.fit_transform(df_dummy['label'].values)\n",
        "\n",
        "# remove rows with missing data\n",
        "df_dummy = df_dummy.replace('?', np.nan)\n",
        "df_dummy_drop_row = df_dummy.dropna()\n",
        "# here we cannot use sklearn.Imputer, since it only accepts numerical values\n",
        "\n",
        "# one-hot encoding\n",
        "df_dummy_drop_row = pd.get_dummies(df_dummy_drop_row)\n",
        "display(df_dummy_drop_row.head())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education-num</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>label</th>\n",
              "      <th>workclass_Federal-gov</th>\n",
              "      <th>workclass_Local-gov</th>\n",
              "      <th>workclass_Private</th>\n",
              "      <th>workclass_Self-emp-inc</th>\n",
              "      <th>workclass_Self-emp-not-inc</th>\n",
              "      <th>workclass_State-gov</th>\n",
              "      <th>workclass_Without-pay</th>\n",
              "      <th>education_10th</th>\n",
              "      <th>education_11th</th>\n",
              "      <th>education_12th</th>\n",
              "      <th>education_1st-4th</th>\n",
              "      <th>education_5th-6th</th>\n",
              "      <th>education_7th-8th</th>\n",
              "      <th>education_9th</th>\n",
              "      <th>education_Assoc-acdm</th>\n",
              "      <th>education_Assoc-voc</th>\n",
              "      <th>education_Bachelors</th>\n",
              "      <th>education_Doctorate</th>\n",
              "      <th>education_HS-grad</th>\n",
              "      <th>education_Masters</th>\n",
              "      <th>education_Preschool</th>\n",
              "      <th>education_Prof-school</th>\n",
              "      <th>education_Some-college</th>\n",
              "      <th>marital-status_Divorced</th>\n",
              "      <th>marital-status_Married-AF-spouse</th>\n",
              "      <th>marital-status_Married-civ-spouse</th>\n",
              "      <th>marital-status_Married-spouse-absent</th>\n",
              "      <th>marital-status_Never-married</th>\n",
              "      <th>marital-status_Separated</th>\n",
              "      <th>marital-status_Widowed</th>\n",
              "      <th>occupation_Adm-clerical</th>\n",
              "      <th>occupation_Armed-Forces</th>\n",
              "      <th>occupation_Craft-repair</th>\n",
              "      <th>...</th>\n",
              "      <th>native-country_Canada</th>\n",
              "      <th>native-country_China</th>\n",
              "      <th>native-country_Columbia</th>\n",
              "      <th>native-country_Cuba</th>\n",
              "      <th>native-country_Dominican-Republic</th>\n",
              "      <th>native-country_Ecuador</th>\n",
              "      <th>native-country_El-Salvador</th>\n",
              "      <th>native-country_England</th>\n",
              "      <th>native-country_France</th>\n",
              "      <th>native-country_Germany</th>\n",
              "      <th>native-country_Greece</th>\n",
              "      <th>native-country_Guatemala</th>\n",
              "      <th>native-country_Haiti</th>\n",
              "      <th>native-country_Holand-Netherlands</th>\n",
              "      <th>native-country_Honduras</th>\n",
              "      <th>native-country_Hong</th>\n",
              "      <th>native-country_Hungary</th>\n",
              "      <th>native-country_India</th>\n",
              "      <th>native-country_Iran</th>\n",
              "      <th>native-country_Ireland</th>\n",
              "      <th>native-country_Italy</th>\n",
              "      <th>native-country_Jamaica</th>\n",
              "      <th>native-country_Japan</th>\n",
              "      <th>native-country_Laos</th>\n",
              "      <th>native-country_Mexico</th>\n",
              "      <th>native-country_Nicaragua</th>\n",
              "      <th>native-country_Outlying-US(Guam-USVI-etc)</th>\n",
              "      <th>native-country_Peru</th>\n",
              "      <th>native-country_Philippines</th>\n",
              "      <th>native-country_Poland</th>\n",
              "      <th>native-country_Portugal</th>\n",
              "      <th>native-country_Puerto-Rico</th>\n",
              "      <th>native-country_Scotland</th>\n",
              "      <th>native-country_South</th>\n",
              "      <th>native-country_Taiwan</th>\n",
              "      <th>native-country_Thailand</th>\n",
              "      <th>native-country_Trinadad&amp;Tobago</th>\n",
              "      <th>native-country_United-States</th>\n",
              "      <th>native-country_Vietnam</th>\n",
              "      <th>native-country_Yugoslavia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>77516</td>\n",
              "      <td>13</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>83311</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>215646</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>234721</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>338409</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 105 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  fnlwgt  ...  native-country_Vietnam  native-country_Yugoslavia\n",
              "0   39   77516  ...                       0                          0\n",
              "1   50   83311  ...                       0                          0\n",
              "2   38  215646  ...                       0                          0\n",
              "3   53  234721  ...                       0                          0\n",
              "4   28  338409  ...                       0                          0\n",
              "\n",
              "[5 rows x 105 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfcwBgs3eywn",
        "colab_type": "text"
      },
      "source": [
        "### Scikit-learn Pipeline\n",
        "When we applied different preprocessing techniques in the previous labs, such as standardization, data preprocessing, or PCA, you learned that we have to reuse the parameters that were obtained during the fitting of the training data to scale and compress any new data, for example, the samples in the separate test dataset. **Scikit-learn Pipeline allows us to fit a model including an arbitrary number of transformation steps and apply it to make predictions about new data.**\n",
        "![Êõø‰ª£ÊñáÂ≠ó](https://i.imgur.com/lkQV1gG.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwBOIxEke4u-",
        "colab_type": "code",
        "outputId": "7596e83a-53cc-47bc-b642-983ceee40ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "#we give an example on how to combine Imputer and OneHotEncoder with KNN or SVM:\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "df_small = df.sample(n=4000, random_state=0)\n",
        "\n",
        "X = df_small.drop('label', axis=1).values\n",
        "y = df_small['label'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# define pipeline with an arbitrary number of transformer in a tuple array\n",
        "pipe_knn = Pipeline([('imr', Imputer(missing_values='NaN', strategy='most_frequent', axis=0)),\n",
        "                     ('ohe', OneHotEncoder(categorical_features=catego_features_idx, \n",
        "                                           n_values=num_values, sparse=False)),\n",
        "                     ('scl', StandardScaler()),\n",
        "                     ('clf', KNeighborsClassifier(n_neighbors=10, p=2, metric='minkowski'))])\n",
        "\n",
        "pipe_svm = Pipeline([('imr', Imputer(missing_values='NaN', strategy='most_frequent', axis=0)),\n",
        "                     ('ohe', OneHotEncoder(categorical_features=catego_features_idx, \n",
        "                                           n_values=num_values, sparse=False)),\n",
        "                     ('scl', StandardScaler()),\n",
        "                     ('clf', SVC(kernel='rbf', random_state=0, gamma=0.001, C=100.0))])\n",
        "\n",
        "# use the pipeline model to train\n",
        "pipe_knn.fit(X_train, y_train)\n",
        "y_pred = pipe_knn.predict(X_test)\n",
        "print('[KNN]')\n",
        "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
        "print('Accuracy: %.4f' % accuracy_score(y_test, y_pred))\n",
        "\n",
        "pipe_svm.fit(X_train, y_train)\n",
        "y_pred = pipe_svm.predict(X_test)\n",
        "print('\\n[SVC]')\n",
        "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
        "print('Accuracy: %.4f' % accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[KNN]\n",
            "Misclassified samples: 158\n",
            "Accuracy: 0.8025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[SVC]\n",
            "Misclassified samples: 134\n",
            "Accuracy: 0.8325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtcm6Fm0e9E_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "36d884f1-426c-416c-f9d2-4559559c12b4"
      },
      "source": [
        "#check whether one-hot encoding is useful or not:\n",
        "pipe_knn = Pipeline([('imr', Imputer(missing_values='NaN', strategy='most_frequent', axis=0)),\n",
        "                     ('scl', StandardScaler()),\n",
        "                     ('clf', KNeighborsClassifier(n_neighbors=10, p=2, metric='minkowski'))])\n",
        "\n",
        "pipe_svm = Pipeline([('imr', Imputer(missing_values='NaN', strategy='most_frequent', axis=0)),\n",
        "                     ('scl', StandardScaler()),\n",
        "                     ('clf', SVC(kernel='rbf', random_state=0, gamma=0.001, C=100.0))])\n",
        "\n",
        "pipe_knn.fit(X_train, y_train)\n",
        "y_pred = pipe_knn.predict(X_test)\n",
        "print('[KNN: no one-hot]')\n",
        "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
        "print('Accuracy: %.4f' % accuracy_score(y_test, y_pred))\n",
        "\n",
        "pipe_svm.fit(X_train, y_train)\n",
        "y_pred = pipe_svm.predict(X_test)\n",
        "print('\\n[SVC: no one-hot]')\n",
        "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
        "print('Accuracy: %.4f' % accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[KNN: no one-hot]\n",
            "Misclassified samples: 156\n",
            "Accuracy: 0.8050\n",
            "\n",
            "[SVC: no one-hot]\n",
            "Misclassified samples: 151\n",
            "Accuracy: 0.8113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnTQ1YdyfDbj",
        "colab_type": "text"
      },
      "source": [
        "As we can see, the performance of KNN does not change much because the model does not prefer specific numerical values. On the other hand, the performance of SVC dropped because it has a weight decay term in the cost function that can be misled when the categorical features are not encoded as one-hot vectors.\n",
        "\n",
        "We can also compare the performance between imputation and dropping rows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5danoARlfEn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "8460f83a-cab1-4f8f-f8cc-ef189ca3fc0a"
      },
      "source": [
        "# keep only data points without NaN features\n",
        "idx = np.isnan(X_train).sum(1) == 0\n",
        "X_train = X_train[idx]\n",
        "y_train = y_train[idx]\n",
        "idx = np.isnan(X_test).sum(1) == 0\n",
        "X_test = X_test[idx]\n",
        "y_test = y_test[idx]\n",
        "\n",
        "pipe_knn = Pipeline([('ohe', OneHotEncoder(categorical_features = catego_features_idx, \n",
        "                                           n_values = num_values, sparse=False)),\n",
        "                     ('scl', StandardScaler()),\n",
        "                     ('clf', KNeighborsClassifier(n_neighbors=10, p=2, metric='minkowski'))])\n",
        "\n",
        "pipe_svm = Pipeline([('ohe', OneHotEncoder(categorical_features = catego_features_idx, \n",
        "                                           n_values = num_values, sparse=False)),\n",
        "                     ('scl', StandardScaler()),\n",
        "                     ('clf', SVC(kernel='rbf', random_state=0, gamma=0.001, C=100.0))])\n",
        "\n",
        "# use the pipeline model to train\n",
        "pipe_knn.fit(X_train, y_train)\n",
        "y_pred = pipe_knn.predict(X_test)\n",
        "print('[KNN: drop row]')\n",
        "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
        "print('Accuracy: %.4f' % accuracy_score(y_test, y_pred))\n",
        "\n",
        "pipe_svm.fit(X_train, y_train)\n",
        "y_pred = pipe_svm.predict(X_test)\n",
        "print('\\n[SVC: drop row]')\n",
        "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
        "print('Accuracy: %.4f' % accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[KNN: drop row]\n",
            "Misclassified samples: 148\n",
            "Accuracy: 0.8008\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[SVC: drop row]\n",
            "Misclassified samples: 126\n",
            "Accuracy: 0.8304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxfrLZxRfIwc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc85b132-6c24-4e48-9b29-fd54a91ef87a"
      },
      "source": [
        "#let's combine SVC pipeline with grid search:\n",
        "pipe_svm = Pipeline([('ohe', OneHotEncoder(categorical_features = catego_features_idx, \n",
        "                                           n_values = num_values, sparse=False)),\n",
        "                     ('scl', StandardScaler()),\n",
        "                     ('clf', SVC(random_state=0))])\n",
        "\n",
        "param_gamma = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
        "param_C = [0.1, 1.0, 10.0, 100.0]\n",
        "\n",
        "# here you can set parameter for different steps \n",
        "# by adding two underlines (__) between step name and parameter name\n",
        "param_grid = [{'clf__C': param_C, \n",
        "               'clf__kernel': ['linear']},\n",
        "              {'clf__C': param_C, \n",
        "               'clf__gamma': param_gamma, \n",
        "               'clf__kernel': ['rbf']}]\n",
        "\n",
        "# set pipe_svm as the estimator\n",
        "gs = GridSearchCV(estimator=pipe_svm, \n",
        "                  param_grid=param_grid, \n",
        "                  scoring='accuracy')\n",
        "\n",
        "gs = gs.fit(X_train, y_train)\n",
        "print('[SVC: grid search]')\n",
        "print('Validation accuracy: %.3f' % gs.best_score_)\n",
        "print(gs.best_params_)\n",
        "\n",
        "clf = gs.best_estimator_\n",
        "clf.fit(X_train, y_train)\n",
        "print('Test accuracy: %.3f' % clf.score(X_test, y_test))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[SVC: grid search]\n",
            "Validation accuracy: 0.835\n",
            "{'clf__C': 100.0, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:373: DeprecationWarning: Passing 'n_values' is deprecated in version 0.20 and will be removed in 0.22. You can use the 'categories' keyword instead. 'n_values=n' corresponds to 'categories=[range(n)] * n_features'.\n",
            "  warnings.warn(msg, DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.830\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}